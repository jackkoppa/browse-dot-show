{"id":"bds-04f","title":"Terraform init timeouts during site deployment","description":"Terraform init is timing out during site deployment. Users have reported needing to manually add higher timeouts. This should be configurable or have sensible defaults.\n\n**Code References:**\n- [`scripts/deploy/site-deploy.ts`](https://github.com/jackkoppa/browse-dot-show/blob/main/scripts/deploy/site-deploy.ts#L433) - terraform init command\n\n**Requirements:**\n- Add configurable timeout for terraform init operations\n- Update deployment scripts to handle longer initialization times\n- Consider making this site-specific if some sites need longer timeouts\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:47.931182-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:47.931182-05:00","external_ref":"gh-124","labels":["bug-report"]}
{"id":"bds-0qf","title":"Clarify and document site-account-mappings.json structure","description":"The structure of `.site-account-mappings.json` is unclear and has caused deployment issues for users. Need better documentation and validation.\n\n**Code References:**\n- [`scripts/utils/site-account-mappings.ts`](https://github.com/jackkoppa/browse-dot-show/blob/main/scripts/utils/site-account-mappings.ts#L4-12) - interface definition\n\n**Requirements:**\n- Document required structure with examples\n- Add validation for site account mappings\n- Provide better error messages when structure is incorrect\n","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-29T12:57:48.631502-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.631502-05:00","external_ref":"gh-128","labels":["documentation","feature-request"]}
{"id":"bds-1k9","title":"Test without external-ref","description":"Test","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:31.395859-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:33.929107-05:00","closed_at":"2025-12-29T12:57:33.929107-05:00","close_reason":"Closed","labels":["bug-report"]}
{"id":"bds-5ag","title":"Transcription times out after 150s or 300s","description":"## Bug Report\n\n**What's wrong?**\nDuring the initial site creation wizard, when downloading and transcribing the first two episodes, the transcription fails with an error that it has timed out after 150s and then on the second try, 300s.\n\nThe test transcription is successful, but the episode transcriptions timeout.\n\nOS is Ubuntu 24.04.1 LTS on WSL\n\nWhisper.cpp is successfully installed with the large-v3-turbo model\n\nI can't see any settings for a timeout value anywhere\n\n**Steps to reproduce:**\n1. Running pnpm site:create on the step \"Generate first episode transcriptions\"\n2. \n3. \n\n**Expected behavior:**\nThe transcription should be successful\n\n**Screenshots/Links:**\n\n`pnpm site:create\n\n\u003e browse-dot-show@0.0.1 site:create /home/xxx/browse-dot-show\n\u003e tsx scripts/create-site.ts\n\nğŸ§ Welcome to the browse.show Site Creator!\n\nâ„¹ï¸  Continuing setup for \u003cSite / podcast details removed\u003e\n\nğŸ“Š Current Progress: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 25% (2/8 complete)\n\n\nğŸ¯ Next Step: Generate first episode transcriptions\n   Process a few episodes locally to test the workflow\n\nâœ” Ready to generate first episode transcriptions? â€º Yes, let's do it now! ğŸš€\n\nâ„¹ï¸  ğŸ™ï¸  Let's setup transcriptions for your first few episodes!\n\nThis will help you see a working searchable site quickly. We'll download\nand transcribe 2 episodes locally (this takes about 10-20 minutes).\n\nâ„¹ï¸  âœ… Found existing Whisper configuration in .env.local\n   â€¢ Whisper path: /home/xxx/whisper.cpp\n   â€¢ Whisper model: large-v3-turbo\n\nâ„¹ï¸  Skipping Whisper setup prompts and using existing configuration...\nâ„¹ï¸  ğŸ§ª Testing your Whisper installation...\nThis may take a moment...\nâ„¹ï¸  ğŸ§ Transcribing welcome message - this might take up to 2 minutes on first run...\nğŸ”§ Executing: /home/xxx/whisper.cpp/build/bin/whisper-cli -m /home/xxx/whisper.cpp/models/ggml-large-v3-turbo.bin -f docs/welcome-to-browse-dot-show.wav\n\nâ„¹ï¸  ğŸ“ Transcription result:\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n[00:00:00.000 --\u003e 00:00:06.000]   Hey, this is Jack. Thanks for trying out Browse.show. Best of luck with your setup.\n[00:00:06.000 --\u003e 00:00:11.000]   And if you hit any problems, please definitely open issues on the GitHub repo.\n[00:00:11.000 --\u003e 00:00:13.000]   We'd love to hear from you. Thanks.\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nâœ… Your local installation of the Whisper model is working correctly ğŸ‰\n\nâœ” Ready to start downloading and transcribing your first 2 episodes? This will take about 10-20 minutes. â€¦ yes\n\nâ„¹ï¸  ğŸµ Processing your first 2 episodes...\nWe'll run this in 3 phases to get accurate timing metrics.\nâ„¹ï¸  ğŸ“¥ Phase 1: Downloading episode audio files...\nğŸš€ Lambda Trigger Tool - Run Ingestion Functions\n==================================================\nFound 1 site(s) in my-sites/, ignoring origin-sites/\n\nğŸ“ Execution Summary:\n   Lambda Function: RSS Feed Retrieval and Audio Download\n   Environment: local\n   Sites: \u003cSite / podcast details removed\u003e\n   Execution Mode: Local (tsx)\n\nğŸ’¡ Equivalent CLI command:\n   NODE_OPTIONS=--max-old-space-size=9728 pnpm tsx scripts/trigger-individual-ingestion-lambda.ts --sites=\u003cSite / podcast details removed\u003e --lambda=rss-retrieval --env=local\n\n========================================\nProcessing site: \u003cSite / podcast details removed\u003e (\u003cSite / podcast details removed\u003e.)\n========================================\nğŸš€ Running RSS Feed Retrieval and Audio Download locally for site: \u003cSite / podcast details removed\u003e\nâœ… âœ… RSS Feed Retrieval and Audio Download completed successfully for \u003cSite / podcast details removed\u003e (1.4s)\n\n==================================================\nğŸ“Š Final Summary\n==================================================\n\nğŸ“ˆ Results:\n   âœ… \u003cSite / podcast details removed\u003e: 1.4s\n\nğŸ“Š Overall Statistics:\n   Success Rate: 1/1 (100.0%)\n   Total Duration: 1.4s\n   Function: RSS Feed Retrieval and Audio Download\n   Environment: local\n\nğŸ‰ All operations completed successfully!\n\nâœ… âœ… Episode download completed!\nâ„¹ï¸  ğŸ™ï¸  Phase 2: Transcribing episodes...\nğŸš€ Lambda Trigger Tool - Run Ingestion Functions\n==================================================\nFound 1 site(s) in my-sites/, ignoring origin-sites/\n\nğŸ“ Execution Summary:\n   Lambda Function: Whisper Audio Processing\n   Environment: local\n   Sites: \u003cSite / podcast details removed\u003e\n   Execution Mode: Local (tsx)\n\nğŸ’¡ Equivalent CLI command:\n   NODE_OPTIONS=--max-old-space-size=9728 pnpm tsx scripts/trigger-individual-ingestion-lambda.ts --sites=\u003cSite / podcast details removed\u003e --lambda=process-audio --env=local\n\n========================================\nProcessing site: \u003cSite / podcast details removed\u003e (\u003cSite / podcast details removed\u003e.)\n========================================\nğŸš€ Running Whisper Audio Processing locally for site: \u003cSite / podcast details removed\u003e\n{\"processId\":\"unknown\",\"timestamp\":\"2025-08-31T12:01:23.375Z\",\"type\":\"START\",\"message\":\"Starting transcription of 2 files\",\"data\":{\"siteId\":\"\u003cSite / podcast details removed\u003e\",\"totalFiles\":2,\"completedFiles\":0,\"totalMinutes\":132.25969375,\"completedMinutes\":0,\"percentComplete\":0}}\nğŸš€ Starting transcription for \u003cSite / podcast details removed\u003e\nâ±ï¸  Transcribing \u003cSite / podcast details removed\u003e... 10.0s elapsed\n...\nâ±ï¸  Transcribing \u003cSite / podcast details removed\u003e... 143.4s elapsed\nâ° Timeout reached (150s), immediately killing whisper process PID 3054\nâŒ Transcription attempt 1/2 failed for \u003cSite / podcast details removed\u003e: Transcription timed out after 150 seconds\nâ±ï¸  Transcribing \u003cSite / podcast details removed\u003e... 153.4s elapsed\nâŒ Whisper command failed with exit code null after 153.54s\nFinal stdout:\n[00:00:00.000 --\u003e 00:00:04.280]   \u003cSite / podcast details removed\u003e\n...\n[00:01:20.600 --\u003e 00:01:25.960]   \u003cSite / podcast details removed\u003e\n\nFinal stderr: whisper_init_from_file_with_params_no_state: loading model from '/home/xxx/whisper.cpp/models/ggml-large-v3-turbo.bin'\nwhisper_init_with_params_no_state: use gpu    = 1\nwhisper_init_with_params_no_state: flash attn = 0\nwhisper_init_with_params_no_state: gpu_device = 0\nwhisper_init_with_params_no_state: dtw        = 0\nwhisper_init_with_params_no_state: devices    = 1\nwhisper_init_with_params_no_state: backends   = 1\nwhisper_model_load: loading model\nwhisper_model_load: n_vocab       = 51866\nwhisper_model_load: n_audio_ctx   = 1500\nwhisper_model_load: n_audio_state = 1280\nwhisper_model_load: n_audio_head  = 20\nwhisper_model_load: n_audio_layer = 32\nwhisper_model_load: n_text_ctx    = 448\nwhisper_model_load: n_text_state  = 1280\nwhisper_model_load: n_text_head   = 20\nwhisper_model_load: n_text_layer  = 4\nwhisper_model_load: n_mels        = 128\nwhisper_model_load: ftype         = 1\nwhisper_model_load: qntvr         = 0\nwhisper_model_load: type          = 5 (large v3)\nwhisper_model_load: adding 1609 extra tokens\nwhisper_model_load: n_langs       = 100\nwhisper_model_load:          CPU total size =  1623.92 MB\nwhisper_model_load: model size    = 1623.92 MB\nwhisper_backend_init_gpu: no GPU found\nwhisper_init_state: kv self size  =   10.49 MB\nwhisper_init_state: kv cross size =   31.46 MB\nwhisper_init_state: kv pad  size  =    7.86 MB\nwhisper_init_state: compute buffer (conv)   =   36.15 MB\nwhisper_init_state: compute buffer (encode) =  212.31 MB\nwhisper_init_state: compute buffer (cross)  =    9.27 MB\nwhisper_init_state: compute buffer (decode) =   99.12 MB\n\nsystem_info: n_threads = 4 / 8 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | OPENMP = 1 | REPACK = 1 |\n\nmain: processing '/tmp/1756641682443-903vv5j3x/audio/\u003cSite / podcast details removed\u003e-podcast/\u003cSite / podcast details removed\u003e' (19200626 samples, 1200.0 sec), 4 threads, 1 processors, 5 beams + best of 5, lang = en, task = transcribe, timestamps = 1 ...\n\n\nğŸš€ Starting transcription for \u003cSite / podcast details removed\u003e using local-whisper.cpp...\nâ±ï¸  Transcribing \u003cSite / podcast details removed\u003e... 10.9s elapsed\n...\nâ±ï¸  Transcribing \u003cSite / podcast details removed\u003e... 298.6s elapsed\nâ° Timeout reached (300s), immediately killing whisper process PID 9413\nâŒ Transcription attempt 2/2 failed for \u003cSite / podcast details removed\u003e: Transcription timed out after 300 seconds\nError processing audio/\u003cSite / podcast details removed\u003e-podcast/\u003cSite / podcast details removed\u003e: Error: Transcription failed after 2 attempts for file: /tmp/1756641682443-903vv5j3x/audio/\u003cSite / podcast details removed\u003e-podcast/\u003cSite / podcast details removed\u003e\nProvider: local-whisper.cpp\nResponse format: srt\nLast error: Transcription timed out after 300 seconds\nFile size: 19200909 bytes\n    at transcribeViaWhisper (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/utils/transcribe-via-whisper.ts:138:15)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async processAudioFile (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/process-new-audio-files-via-whisper.ts:622:26)\n    at async handler (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/process-new-audio-files-via-whisper.ts:971:32)\nError processing file audio/\u003cSite / podcast details removed\u003e-podcast/\u003cSite / podcast details removed\u003e: Error: Transcription failed after 2 attempts for file: /tmp/1756641682443-903vv5j3x/audio/\u003cSite / podcast details removed\u003e-podcast/\u003cSite / podcast details removed\u003e\nProvider: local-whisper.cpp\nResponse format: srt\nLast error: Transcription timed out after 300 seconds\nFile size: 19200909 bytes\n    at transcribeViaWhisper (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/utils/transcribe-via-whisper.ts:138:15)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async processAudioFile (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/process-new-audio-files-via-whisper.ts:622:26)\n    at async handler (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/process-new-audio-files-via-whisper.ts:971:32)\nâ±ï¸  Transcribing \u003cSite / podcast details removed\u003e... 309.5s elapsed\nâŒ Whisper command failed with exit code null after 309.55s\nFinal stdout:\n[00:00:00.000 --\u003e 00:00:04.280]   \u003cSite / podcast details removed\u003e\n...\n[00:02:25.000 --\u003e 00:02:30.360]   \u003cSite / podcast details removed\u003e\n\nFinal stderr: whisper_init_from_file_with_params_no_state: loading model from '/home/xxx/whisper.cpp/models/ggml-large-v3-turbo.bin'\nwhisper_init_with_params_no_state: use gpu    = 1\nwhisper_init_with_params_no_state: flash attn = 0\nwhisper_init_with_params_no_state: gpu_device = 0\nwhisper_init_with_params_no_state: dtw        = 0\nwhisper_init_with_params_no_state: devices    = 1\nwhisper_init_with_params_no_state: backends   = 1\nwhisper_model_load: loading model\nwhisper_model_load: n_vocab       = 51866\nwhisper_model_load: n_audio_ctx   = 1500\nwhisper_model_load: n_audio_state = 1280\nwhisper_model_load: n_audio_head  = 20\nwhisper_model_load: n_audio_layer = 32\nwhisper_model_load: n_text_ctx    = 448\nwhisper_model_load: n_text_state  = 1280\nwhisper_model_load: n_text_head   = 20\nwhisper_model_load: n_text_layer  = 4\nwhisper_model_load: n_mels        = 128\nwhisper_model_load: ftype         = 1\nwhisper_model_load: qntvr         = 0\nwhisper_model_load: type          = 5 (large v3)\nwhisper_model_load: adding 1609 extra tokens\nwhisper_model_load: n_langs       = 100\nwhisper_model_load:          CPU total size =  1623.92 MB\nwhisper_model_load: model size    = 1623.92 MB\nwhisper_backend_init_gpu: no GPU found\nwhisper_init_state: kv self size  =   10.49 MB\nwhisper_init_state: kv cross size =   31.46 MB\nwhisper_init_state: kv pad  size  =    7.86 MB\nwhisper_init_state: compute buffer (conv)   =   36.15 MB\nwhisper_init_state: compute buffer (encode) =  212.31 MB\nwhisper_init_state: compute buffer (cross)  =    9.27 MB\nwhisper_init_state: compute buffer (decode) =   99.12 MB\n\nsystem_info: n_threads = 4 / 8 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | OPENMP = 1 | REPACK = 1 |`\n\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:48.805848-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.805848-05:00","external_ref":"gh-134","labels":["bug-report"]}
{"id":"bds-5lh","title":"Test issue to verify prefix change","description":"This is a test issue to verify the prefix has been changed to bds-","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T12:55:15.238047-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:55:16.635836-05:00","closed_at":"2025-12-29T12:55:16.635836-05:00","close_reason":"Closed"}
{"id":"bds-6zm","title":"Test with external-ref","description":"Test","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:47.391287-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:51.630882-05:00","closed_at":"2025-12-29T12:57:51.630882-05:00","close_reason":"Closed","external_ref":"gh-999"}
{"id":"bds-a45","title":"Move origin-sites directory to separate fork to reduce repo size","description":"The origin-sites directory contains many unnecessary images and assets that every fork downloads. Should be moved to separate repository.\n\n**Code References:**\n- [`sites/origin-sites/`](https://github.com/jackkoppa/browse-dot-show/tree/main/sites/origin-sites) - entire directory\n\n**Requirements:**\n- Create separate repository for example sites\n- Update documentation to reference example sites repository\n- Ensure template-site remains in main repository\n- Update site discovery logic if needed\n","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-29T12:57:47.753117-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:47.753117-05:00","external_ref":"gh-129","labels":["feature-request","planned-feature"]}
{"id":"bds-ajy","title":"Test with external-ref","description":"Test","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:31.65166-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:47.288754-05:00","closed_at":"2025-12-29T12:57:33.934445-05:00","close_reason":"Closed","external_ref":""}
{"id":"bds-bgn","title":"Test with no-daemon","description":"Test","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-29T12:57:21.414529-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:21.414529-05:00"}
{"id":"bds-cyk","title":"Fix hardcoded values in automation role deployment","description":"Test description\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:34.776809-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:34.776809-05:00","external_ref":"gh-123","labels":["bug-report"]}
{"id":"bds-drg","title":"Test issue after daemon stop","description":"Test","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:03.813957-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:07.062118-05:00","closed_at":"2025-12-29T12:57:07.062118-05:00","close_reason":"Closed"}
{"id":"bds-g9x","title":"Test issue","description":"Test","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:03.465747-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:07.023729-05:00","closed_at":"2025-12-29T12:57:07.023729-05:00","close_reason":"Closed"}
{"id":"bds-k92","title":"Site deploy does not work correctly","description":"## Bug Report\n\n**What's wrong?**\n\nDeployment to AWS fails\n\n**Steps to reproduce:**\n\n1. Run deploy to AWS step\n\n**Expected behavior:**\n\nIt should work :) Not sure what the issue is as even when I manually run source filename for the env files it does not pick up that these environment variables are set.\n\nThere is no issue with the AWS credentials as I was able to bootstrap the Terraform state bucket (with the change in https://github.com/jackkoppa/browse-dot-show/pull/100\n\n**Screenshots/Links:**\n\nMy configuration is at https://github.com/trevorrea/browse-dot-show\n\nâœ” Ready to setup aws deployment? â€º Yes, let's do it now! ğŸš€\n\nâ„¹ï¸  ğŸš€ Let's deploy your site to AWS!\n\nThis will set up your podcast site with:\n  â€¢ S3 static hosting with global CDN\n  â€¢ Lambda functions for search and processing\n  â€¢ Automatic SSL certificate\n  â€¢ Your custom browse.show subdomain\n\nâ„¹ï¸  ğŸ” Checking AWS CLI installation...\nğŸ”§ Executing: aws --version\nâœ… âœ… AWS CLI is installed\nâ„¹ï¸  ğŸ“‹ Found existing AWS configuration file...\nâ„¹ï¸  Testing existing profile: iwltr-deploy\nâœ… âœ… Existing AWS profile \"iwltr-deploy\" is working!\nâœ… âœ… AWS credentials are configured and ready!\nâ„¹ï¸  ğŸ” Checking deployment prerequisites...\n\nâ„¹ï¸  Checking required tools...\nğŸ”§ Executing: terraform --version\nâœ… âœ… Terraform 1.12 is installed\nâ„¹ï¸  Checking environment variables...\nâŒ âŒ OPENAI_API_KEY environment variable is missing\n\nThis is required for:\n  â€¢ Podcast episode transcription\n  â€¢ Search functionality\n\nâœ” Do you have an OpenAI API key available? â€¦ yes\nâœ” Please enter your OpenAI API key: â€¦ **********\n\nâ„¹ï¸  ğŸ”§ Adding API key to your .env files...\n\nPlease add this line to the following files:\nOPENAI_API_KEY=\"sk-default\"\n\nFiles to update:\n  1. .env.local (for local development)\n  2. .env.lambda-prod-build (for production deployment)\n\nâœ” Have you added the OPENAI_API_KEY to both .env files? â€¦ yes\nâœ… âœ… OpenAI API key configured for this session\nâ„¹ï¸  â„¹ï¸  AWS region set to default: us-east-1\nâ„¹ï¸  Running comprehensive prerequisite checks...\nğŸ”§ Executing: tsx scripts/deploy/check-prerequisites.ts\nâŒ Command failed with exit code 1\n   stderr: âŒ âŒ Site AWS SSO Configuration: AWS_PROFILE not found. Please ensure your site .env.aws-sso file contains AWS_PROFILE=your-profile-name\nâŒ âŒ AWS SSO Authentication: AWS_PROFILE not set. Please ensure your site .env.aws-sso file contains AWS_PROFILE=your-profile-name\nâŒ âŒ Some prerequisites are not met. Please fix the issues above before deploying.\n\nâŒ âŒ Prerequisite check failed\n\nâ„¹ï¸  Some prerequisites may not be met. Common issues:\n  â€¢ AWS CLI not configured properly\n  â€¢ Missing required permissions\n  â€¢ Network connectivity issues\n\nâ„¹ï¸  You can try to continue anyway, but deployment may fail.\nâœ” Would you like to continue despite the prerequisite issues? â€¦ yes\nâœ… âœ… Prerequisites and environment are ready!\nâ„¹ï¸  ğŸ—ï¸  Setting up Terraform state management...\n\nThis creates secure, shared storage for your site's infrastructure state.\nIt's a one-time setup that enables safe infrastructure management.\n\nâ„¹ï¸  Checking if Terraform state is already configured...\nâœ… âœ… Terraform state bucket already exists: browse-dot-show-iwltr-tf-state\nâœ… âœ… Terraform backend configuration files are ready\nâœ… âœ… Terraform state management is ready!\n\nâ„¹ï¸  ğŸš€ Ready to deploy your site infrastructure!\n\nThis will deploy your complete podcast site with:\n  â€¢ S3 bucket for static hosting\n  â€¢ CloudFront CDN for global distribution\n  â€¢ Lambda functions for search and processing\n  â€¢ SSL certificate for secure HTTPS\n  â€¢ DNS configuration for your browse.show subdomain\n\nâ±ï¸  Estimated deployment time: 10-15 minutes\nğŸ’° Estimated monthly cost: $10-35 (depending on usage)\n\nâœ” Ready to deploy your podcast site to AWS? â€¦ yes\nâ„¹ï¸  Setting up deployment environment...\nâ„¹ï¸  Using AWS profile: iwltr-deploy\n\nâ„¹ï¸  ğŸš€ Starting deployment...\nâ„¹ï¸  This may take 10-15 minutes. You can watch the progress below.\n\nâŒ âŒ Deployment encountered an error\n\nError details:\nrequire is not defined\n\n\n---\n**Note:** This issue is vague and may be superseded by more specific deployment bugs (#123-128). Please verify if still relevant.\n","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-29T12:57:49.160927-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:49.160927-05:00","external_ref":"gh-101","labels":["bug-report"]}
{"id":"bds-kbo","title":"FFmpeg layer creation script has directory issues","description":"The script to create FFmpeg layers puts files in wrong directory and errors out during execution. This was discovered during a user deployment attempt.\n\n**Code References:**\n- [`terraform/sites/lambda-layers/2-prepare-ffmpeg-layer.ts`](https://github.com/jackkoppa/browse-dot-show/blob/main/terraform/sites/lambda-layers/2-prepare-ffmpeg-layer.ts#L18-21) - directory paths\n\n**Requirements:**\n- Fix directory structure in ffmpeg layer preparation script\n- Ensure proper error handling and cleanup\n- Test layer creation process end-to-end\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:49.339316-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:49.339316-05:00","external_ref":"gh-126","labels":["bug-report"]}
{"id":"bds-oiq","title":"Terraform deployment expects origin-sites instead of my-sites structure","description":"The deployment scripts hardcode paths to `origin-sites` directory but should support `my-sites` structure for user sites.\n\n**Code References:**\n- [`scripts/deploy/site-deploy.ts`](https://github.com/jackkoppa/browse-dot-show/blob/main/scripts/deploy/site-deploy.ts#L416-417) - hardcoded origin-sites paths\n\n**Requirements:**\n- Update deployment scripts to check my-sites first, then fallback to origin-sites\n- Ensure backend.tfbackend and prod.tfvars are found in correct directory\n- Test with my-sites structure\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:48.278902-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.278902-05:00","external_ref":"gh-125","labels":["bug-report"]}
{"id":"bds-v9u","title":"Show podcast name and cover art in search results for multi-feed sites","description":"For sites with multiple podcast feeds, search results should show which podcast each result comes from to help users distinguish sources.\n\n**Requirements:**\n- Add podcast name display to search result components\n- Optionally show podcast cover art in results\n- Make this configurable for single vs multi-feed sites\n- Update search index to include podcast metadata if needed\n","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-29T12:57:48.984095-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.984095-05:00","external_ref":"gh-131","labels":["feature-request","planned-feature"]}
{"id":"bds-vu2","title":"Lambda layers over 50MB need S3 upload instead of file upload","description":"FFmpeg layer is over 50MB and can't be loaded from zip file. A user (@trevorrea) had to manually upload to S3 and import into terraform state. Code should automatically upload to S3 and reference S3 object instead of filename.\n\n**Code References:**\n- [`terraform/sites/main.tf`](https://github.com/jackkoppa/browse-dot-show/blob/main/terraform/sites/main.tf#L77-86) - ffmpeg layer resource\n\n**Requirements:**\n- Automatically upload large layers to S3 during terraform deployment\n- Update terraform to reference S3 object instead of local file\n- Add lifecycle management to ignore filename changes when using S3\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:48.458109-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.458109-05:00","external_ref":"gh-127","labels":["bug-report"]}
{"id":"bds-zq6","title":"Re-attempt to add speaker diarization to transcripts","description":"## Feature Request\n\n**What feature would you like?**\nIdentify speakers in transcription\n\n**Why is this useful?**\nEasier to read transcripts when broken down this way. Can likely add filtering by speaker in the future, if it works well\n\n**Additional context:**\n* As of 2025-08-05, this isn't currently prioritized. I had attempted it when first setting up http://listenfairplay.com/ - at the time, I was primarily using the OpenAI API, which doesn't easily support this. I also explored https://whisperapi.com/, which could potentially support it.\n* I then attempted the local setup following this guide: https://github.com/ggml-org/whisper.cpp?tab=readme-ov-file#speaker-segmentation-via-tinydiarize-experimental\n* For listenfairplay, this worked poorly - likely in part because the show plays lots of clips (that are not the 3 main panelists) - and so the diarization often missed when speakers changed\n* In the end, I went with simply breaking up transcripts into searchable chunks by time (e.g. \"once a chunk is at least 7 seconds, end it after the next sentence-ending punctuation\")\n* This has _mostly_ worked well enough - and there's a decent amount of search indexing + UI behaviors that we'll need to update if we're able to get diarization working\n* So @jackkoppa is currently working on other things - but if someone is interested enough in this, please feel free to start experimenting, and happy to give feedback on any initial attempts!\n\n","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-29T12:57:48.102594-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.102594-05:00","external_ref":"gh-111","labels":["feature-request","help-wanted"]}
