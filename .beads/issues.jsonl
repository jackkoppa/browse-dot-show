{"id":"bds-04f","title":"Terraform init timeouts during site deployment","description":"Terraform init is timing out during site deployment. Users have reported needing to manually add higher timeouts. This should be configurable or have sensible defaults.\n\n**Code References:**\n- [`scripts/deploy/site-deploy.ts`](https://github.com/jackkoppa/browse-dot-show/blob/main/scripts/deploy/site-deploy.ts#L433) - terraform init command\n\n**Requirements:**\n- Add configurable timeout for terraform init operations\n- Update deployment scripts to handle longer initialization times\n- Consider making this site-specific if some sites need longer timeouts\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:47.931182-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:47.931182-05:00","external_ref":"gh-124","labels":["bug-report"]}
{"id":"bds-0qf","title":"Clarify and document site-account-mappings.json structure","description":"The structure of `.site-account-mappings.json` is unclear and has caused deployment issues for users. Need better documentation and validation.\n\n**Code References:**\n- [`scripts/utils/site-account-mappings.ts`](https://github.com/jackkoppa/browse-dot-show/blob/main/scripts/utils/site-account-mappings.ts#L4-12) - interface definition\n\n**Requirements:**\n- Document required structure with examples\n- Add validation for site account mappings\n- Provide better error messages when structure is incorrect\n","status":"open","priority":2,"issue_type":"feature","created_at":"2025-12-29T12:57:48.631502-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.631502-05:00","external_ref":"gh-128","labels":["documentation","feature-request"]}
{"id":"bds-1k9","title":"Test without external-ref","description":"Test","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:31.395859-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:59:24.218199-05:00","closed_at":"2025-12-29T12:59:24.218199-05:00","close_reason":"Closed","labels":["bug-report"]}
{"id":"bds-3xv","title":"Update aws-architecture diagram with current state","description":"## Outdated Items in diagrams/aws-architecture.drawio\n\nThe current diagram has several outdated references:\n\n1. **Project name**: Diagram says 'Listen Fair Play' - should be 'browse.show'\n2. **Search library**: Diagram mentions 'FlexSearch index' - now uses **Orama**\n3. **Index file name**: Diagram shows 'search_index.db' - now 'orama_index.msp' (MsgPackR + zstd compressed)\n4. **README.md**: Also references 'FlexSearch SQLite index' - should be Orama\n\n## Files to Update\n- diagrams/aws-architecture.drawio\n- diagrams/aws-architecture.drawio.png (re-export after .drawio update)\n- diagrams/README.md\n\n## Note\nThis can be done after the Search Orchestration work, which will require new diagrams anyway. May make sense to update everything at once.","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-29T14:57:26.329019-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T14:57:26.329019-05:00"}
{"id":"bds-5ag","title":"Transcription times out after 150s or 300s","description":"## Bug Report\n\n**What's wrong?**\nDuring the initial site creation wizard, when downloading and transcribing the first two episodes, the transcription fails with an error that it has timed out after 150s and then on the second try, 300s.\n\nThe test transcription is successful, but the episode transcriptions timeout.\n\nOS is Ubuntu 24.04.1 LTS on WSL\n\nWhisper.cpp is successfully installed with the large-v3-turbo model\n\nI can't see any settings for a timeout value anywhere\n\n**Steps to reproduce:**\n1. Running pnpm site:create on the step \"Generate first episode transcriptions\"\n2. \n3. \n\n**Expected behavior:**\nThe transcription should be successful\n\n**Screenshots/Links:**\n\n`pnpm site:create\n\n\u003e browse-dot-show@0.0.1 site:create /home/xxx/browse-dot-show\n\u003e tsx scripts/create-site.ts\n\nüéß Welcome to the browse.show Site Creator!\n\n‚ÑπÔ∏è  Continuing setup for \u003cSite / podcast details removed\u003e\n\nüìä Current Progress: [‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 25% (2/8 complete)\n\n\nüéØ Next Step: Generate first episode transcriptions\n   Process a few episodes locally to test the workflow\n\n‚úî Ready to generate first episode transcriptions? ‚Ä∫ Yes, let's do it now! üöÄ\n\n‚ÑπÔ∏è  üéôÔ∏è  Let's setup transcriptions for your first few episodes!\n\nThis will help you see a working searchable site quickly. We'll download\nand transcribe 2 episodes locally (this takes about 10-20 minutes).\n\n‚ÑπÔ∏è  ‚úÖ Found existing Whisper configuration in .env.local\n   ‚Ä¢ Whisper path: /home/xxx/whisper.cpp\n   ‚Ä¢ Whisper model: large-v3-turbo\n\n‚ÑπÔ∏è  Skipping Whisper setup prompts and using existing configuration...\n‚ÑπÔ∏è  üß™ Testing your Whisper installation...\nThis may take a moment...\n‚ÑπÔ∏è  üéß Transcribing welcome message - this might take up to 2 minutes on first run...\nüîß Executing: /home/xxx/whisper.cpp/build/bin/whisper-cli -m /home/xxx/whisper.cpp/models/ggml-large-v3-turbo.bin -f docs/welcome-to-browse-dot-show.wav\n\n‚ÑπÔ∏è  üìù Transcription result:\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n[00:00:00.000 --\u003e 00:00:06.000]   Hey, this is Jack. Thanks for trying out Browse.show. Best of luck with your setup.\n[00:00:06.000 --\u003e 00:00:11.000]   And if you hit any problems, please definitely open issues on the GitHub repo.\n[00:00:11.000 --\u003e 00:00:13.000]   We'd love to hear from you. Thanks.\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n‚úÖ Your local installation of the Whisper model is working correctly üéâ\n\n‚úî Ready to start downloading and transcribing your first 2 episodes? This will take about 10-20 minutes. ‚Ä¶ yes\n\n‚ÑπÔ∏è  üéµ Processing your first 2 episodes...\nWe'll run this in 3 phases to get accurate timing metrics.\n‚ÑπÔ∏è  üì• Phase 1: Downloading episode audio files...\nüöÄ Lambda Trigger Tool - Run Ingestion Functions\n==================================================\nFound 1 site(s) in my-sites/, ignoring origin-sites/\n\nüìç Execution Summary:\n   Lambda Function: RSS Feed Retrieval and Audio Download\n   Environment: local\n   Sites: \u003cSite / podcast details removed\u003e\n   Execution Mode: Local (tsx)\n\nüí° Equivalent CLI command:\n   NODE_OPTIONS=--max-old-space-size=9728 pnpm tsx scripts/trigger-individual-ingestion-lambda.ts --sites=\u003cSite / podcast details removed\u003e --lambda=rss-retrieval --env=local\n\n========================================\nProcessing site: \u003cSite / podcast details removed\u003e (\u003cSite / podcast details removed\u003e.)\n========================================\nüöÄ Running RSS Feed Retrieval and Audio Download locally for site: \u003cSite / podcast details removed\u003e\n‚úÖ ‚úÖ RSS Feed Retrieval and Audio Download completed successfully for \u003cSite / podcast details removed\u003e (1.4s)\n\n==================================================\nüìä Final Summary\n==================================================\n\nüìà Results:\n   ‚úÖ \u003cSite / podcast details removed\u003e: 1.4s\n\nüìä Overall Statistics:\n   Success Rate: 1/1 (100.0%)\n   Total Duration: 1.4s\n   Function: RSS Feed Retrieval and Audio Download\n   Environment: local\n\nüéâ All operations completed successfully!\n\n‚úÖ ‚úÖ Episode download completed!\n‚ÑπÔ∏è  üéôÔ∏è  Phase 2: Transcribing episodes...\nüöÄ Lambda Trigger Tool - Run Ingestion Functions\n==================================================\nFound 1 site(s) in my-sites/, ignoring origin-sites/\n\nüìç Execution Summary:\n   Lambda Function: Whisper Audio Processing\n   Environment: local\n   Sites: \u003cSite / podcast details removed\u003e\n   Execution Mode: Local (tsx)\n\nüí° Equivalent CLI command:\n   NODE_OPTIONS=--max-old-space-size=9728 pnpm tsx scripts/trigger-individual-ingestion-lambda.ts --sites=\u003cSite / podcast details removed\u003e --lambda=process-audio --env=local\n\n========================================\nProcessing site: \u003cSite / podcast details removed\u003e (\u003cSite / podcast details removed\u003e.)\n========================================\nüöÄ Running Whisper Audio Processing locally for site: \u003cSite / podcast details removed\u003e\n{\"processId\":\"unknown\",\"timestamp\":\"2025-08-31T12:01:23.375Z\",\"type\":\"START\",\"message\":\"Starting transcription of 2 files\",\"data\":{\"siteId\":\"\u003cSite / podcast details removed\u003e\",\"totalFiles\":2,\"completedFiles\":0,\"totalMinutes\":132.25969375,\"completedMinutes\":0,\"percentComplete\":0}}\nüöÄ Starting transcription for \u003cSite / podcast details removed\u003e\n‚è±Ô∏è  Transcribing \u003cSite / podcast details removed\u003e... 10.0s elapsed\n...\n‚è±Ô∏è  Transcribing \u003cSite / podcast details removed\u003e... 143.4s elapsed\n‚è∞ Timeout reached (150s), immediately killing whisper process PID 3054\n‚ùå Transcription attempt 1/2 failed for \u003cSite / podcast details removed\u003e: Transcription timed out after 150 seconds\n‚è±Ô∏è  Transcribing \u003cSite / podcast details removed\u003e... 153.4s elapsed\n‚ùå Whisper command failed with exit code null after 153.54s\nFinal stdout:\n[00:00:00.000 --\u003e 00:00:04.280]   \u003cSite / podcast details removed\u003e\n...\n[00:01:20.600 --\u003e 00:01:25.960]   \u003cSite / podcast details removed\u003e\n\nFinal stderr: whisper_init_from_file_with_params_no_state: loading model from '/home/xxx/whisper.cpp/models/ggml-large-v3-turbo.bin'\nwhisper_init_with_params_no_state: use gpu    = 1\nwhisper_init_with_params_no_state: flash attn = 0\nwhisper_init_with_params_no_state: gpu_device = 0\nwhisper_init_with_params_no_state: dtw        = 0\nwhisper_init_with_params_no_state: devices    = 1\nwhisper_init_with_params_no_state: backends   = 1\nwhisper_model_load: loading model\nwhisper_model_load: n_vocab       = 51866\nwhisper_model_load: n_audio_ctx   = 1500\nwhisper_model_load: n_audio_state = 1280\nwhisper_model_load: n_audio_head  = 20\nwhisper_model_load: n_audio_layer = 32\nwhisper_model_load: n_text_ctx    = 448\nwhisper_model_load: n_text_state  = 1280\nwhisper_model_load: n_text_head   = 20\nwhisper_model_load: n_text_layer  = 4\nwhisper_model_load: n_mels        = 128\nwhisper_model_load: ftype         = 1\nwhisper_model_load: qntvr         = 0\nwhisper_model_load: type          = 5 (large v3)\nwhisper_model_load: adding 1609 extra tokens\nwhisper_model_load: n_langs       = 100\nwhisper_model_load:          CPU total size =  1623.92 MB\nwhisper_model_load: model size    = 1623.92 MB\nwhisper_backend_init_gpu: no GPU found\nwhisper_init_state: kv self size  =   10.49 MB\nwhisper_init_state: kv cross size =   31.46 MB\nwhisper_init_state: kv pad  size  =    7.86 MB\nwhisper_init_state: compute buffer (conv)   =   36.15 MB\nwhisper_init_state: compute buffer (encode) =  212.31 MB\nwhisper_init_state: compute buffer (cross)  =    9.27 MB\nwhisper_init_state: compute buffer (decode) =   99.12 MB\n\nsystem_info: n_threads = 4 / 8 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | OPENMP = 1 | REPACK = 1 |\n\nmain: processing '/tmp/1756641682443-903vv5j3x/audio/\u003cSite / podcast details removed\u003e-podcast/\u003cSite / podcast details removed\u003e' (19200626 samples, 1200.0 sec), 4 threads, 1 processors, 5 beams + best of 5, lang = en, task = transcribe, timestamps = 1 ...\n\n\nüöÄ Starting transcription for \u003cSite / podcast details removed\u003e using local-whisper.cpp...\n‚è±Ô∏è  Transcribing \u003cSite / podcast details removed\u003e... 10.9s elapsed\n...\n‚è±Ô∏è  Transcribing \u003cSite / podcast details removed\u003e... 298.6s elapsed\n‚è∞ Timeout reached (300s), immediately killing whisper process PID 9413\n‚ùå Transcription attempt 2/2 failed for \u003cSite / podcast details removed\u003e: Transcription timed out after 300 seconds\nError processing audio/\u003cSite / podcast details removed\u003e-podcast/\u003cSite / podcast details removed\u003e: Error: Transcription failed after 2 attempts for file: /tmp/1756641682443-903vv5j3x/audio/\u003cSite / podcast details removed\u003e-podcast/\u003cSite / podcast details removed\u003e\nProvider: local-whisper.cpp\nResponse format: srt\nLast error: Transcription timed out after 300 seconds\nFile size: 19200909 bytes\n    at transcribeViaWhisper (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/utils/transcribe-via-whisper.ts:138:15)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async processAudioFile (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/process-new-audio-files-via-whisper.ts:622:26)\n    at async handler (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/process-new-audio-files-via-whisper.ts:971:32)\nError processing file audio/\u003cSite / podcast details removed\u003e-podcast/\u003cSite / podcast details removed\u003e: Error: Transcription failed after 2 attempts for file: /tmp/1756641682443-903vv5j3x/audio/\u003cSite / podcast details removed\u003e-podcast/\u003cSite / podcast details removed\u003e\nProvider: local-whisper.cpp\nResponse format: srt\nLast error: Transcription timed out after 300 seconds\nFile size: 19200909 bytes\n    at transcribeViaWhisper (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/utils/transcribe-via-whisper.ts:138:15)\n    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\n    at async processAudioFile (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/process-new-audio-files-via-whisper.ts:622:26)\n    at async handler (/home/xxx/browse-dot-show/packages/ingestion/process-audio-lambda/process-new-audio-files-via-whisper.ts:971:32)\n‚è±Ô∏è  Transcribing \u003cSite / podcast details removed\u003e... 309.5s elapsed\n‚ùå Whisper command failed with exit code null after 309.55s\nFinal stdout:\n[00:00:00.000 --\u003e 00:00:04.280]   \u003cSite / podcast details removed\u003e\n...\n[00:02:25.000 --\u003e 00:02:30.360]   \u003cSite / podcast details removed\u003e\n\nFinal stderr: whisper_init_from_file_with_params_no_state: loading model from '/home/xxx/whisper.cpp/models/ggml-large-v3-turbo.bin'\nwhisper_init_with_params_no_state: use gpu    = 1\nwhisper_init_with_params_no_state: flash attn = 0\nwhisper_init_with_params_no_state: gpu_device = 0\nwhisper_init_with_params_no_state: dtw        = 0\nwhisper_init_with_params_no_state: devices    = 1\nwhisper_init_with_params_no_state: backends   = 1\nwhisper_model_load: loading model\nwhisper_model_load: n_vocab       = 51866\nwhisper_model_load: n_audio_ctx   = 1500\nwhisper_model_load: n_audio_state = 1280\nwhisper_model_load: n_audio_head  = 20\nwhisper_model_load: n_audio_layer = 32\nwhisper_model_load: n_text_ctx    = 448\nwhisper_model_load: n_text_state  = 1280\nwhisper_model_load: n_text_head   = 20\nwhisper_model_load: n_text_layer  = 4\nwhisper_model_load: n_mels        = 128\nwhisper_model_load: ftype         = 1\nwhisper_model_load: qntvr         = 0\nwhisper_model_load: type          = 5 (large v3)\nwhisper_model_load: adding 1609 extra tokens\nwhisper_model_load: n_langs       = 100\nwhisper_model_load:          CPU total size =  1623.92 MB\nwhisper_model_load: model size    = 1623.92 MB\nwhisper_backend_init_gpu: no GPU found\nwhisper_init_state: kv self size  =   10.49 MB\nwhisper_init_state: kv cross size =   31.46 MB\nwhisper_init_state: kv pad  size  =    7.86 MB\nwhisper_init_state: compute buffer (conv)   =   36.15 MB\nwhisper_init_state: compute buffer (encode) =  212.31 MB\nwhisper_init_state: compute buffer (cross)  =    9.27 MB\nwhisper_init_state: compute buffer (decode) =   99.12 MB\n\nsystem_info: n_threads = 4 / 8 | WHISPER : COREML = 0 | OPENVINO = 0 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | OPENMP = 1 | REPACK = 1 |`\n\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:48.805848-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.805848-05:00","external_ref":"gh-134","labels":["bug-report"]}
{"id":"bds-5lh","title":"Test issue to verify prefix change","description":"This is a test issue to verify the prefix has been changed to bds-","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T12:55:15.238047-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:59:24.373945-05:00","closed_at":"2025-12-29T12:59:24.373945-05:00","close_reason":"Closed"}
{"id":"bds-6zm","title":"Test with external-ref","description":"Test","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:47.391287-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:59:24.114444-05:00","closed_at":"2025-12-29T12:59:24.114444-05:00","close_reason":"Closed","external_ref":"gh-999"}
{"id":"bds-7dq","title":"Log client-side search timeouts via goatcounter","description":"## Objective\nTrack how often users experience search timeouts so we can monitor cold start impact.\n\n## Context\nWith search orchestration, cold starts may occasionally exceed API Gateway's 30s limit. We need visibility into how often this affects real users.\n\n## Implementation\n- When client receives a timeout/error from search API, log a goatcounter event\n- Event format: `[site_id] Search Timeout` or similar\n- Include metadata if goatcounter supports it (e.g., was this likely a cold start?)\n\n## Monitoring\n- Check goatcounter dashboard for timeout event trends\n- If timeout rate is high, consider more aggressive warming\n\n## Notes\nThis complements server-side error monitoring (bds-kmy).\nDiscovered during bds-a8r.1 planning.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-29T15:21:44.158482-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T15:21:44.158482-05:00"}
{"id":"bds-80b","title":"Clean up initial Beads setup and migration documentation files","description":"During the initial Beads setup and GitHub issues migration, several temporary documentation files and scripts were created:\n\n**Files to clean up:**\n- BEADS_UI_SETUP.md - Initial setup guide (can be removed, info is in .beads/README.md)\n- ISSUE_MIGRATION_ANALYSIS.md - Pre-migration analysis (no longer needed)\n- MIGRATION_COMPLETE.md - Migration summary (no longer needed)\n- REVIEW_ISSUES_WEB_UI.md - Web UI review guide (can be removed, basic usage is sufficient)\n- migrate_issues.sh - Migration script (no longer needed)\n\n**Files to keep:**\n- start-beads-ui.sh - Useful convenience script for starting the UI\n- .beads/README.md - Official Beads documentation\n\nOnce cleanup is complete, this issue can be closed.","status":"closed","priority":3,"issue_type":"chore","created_at":"2025-12-29T13:18:28.486369-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T13:18:29.516583-05:00","closed_at":"2025-12-29T13:18:29.51659-05:00"}
{"id":"bds-a45","title":"Move origin-sites directory to separate fork to reduce repo size","description":"The origin-sites directory contains many unnecessary images and assets that every fork downloads. Should be moved to separate repository.\n\n**Code References:**\n- [`sites/origin-sites/`](https://github.com/jackkoppa/browse-dot-show/tree/main/sites/origin-sites) - entire directory\n\n**Requirements:**\n- Create separate repository for example sites\n- Update documentation to reference example sites repository\n- Ensure template-site remains in main repository\n- Update site discovery logic if needed\n","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-29T12:57:47.753117-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:47.753117-05:00","external_ref":"gh-129","labels":["feature-request","planned-feature"]}
{"id":"bds-a8r","title":"Search Orchestration Lambda","description":"## Overview\n\nAdd an optional search orchestration Lambda that enables distributed search across multiple search Lambdas. This is required for:\n1. **Large sites** that exceed the single Lambda memory limit (~10GB for index files)\n2. **Authenticated feed support** (future Epic) where public and private indexes need coordinated searching\n\n## Problem Statement\n\nCurrently, each browse.show site has a single search Lambda that:\n- Downloads the Orama search index from S3 on cold start\n- Loads the entire index into memory\n- Has a hard cap of ~10GB (max Lambda memory) for index size\n\n**This limit has already been hit.** The `limitedresources` site (~900 hours of audio) exceeded 10GB memory during indexing and cannot currently be fully indexed. The `myfavoritemurder` site is at 8GB+ and approaching the limit.\n\n## Implementation Priority\n\n**Phase 1: Episode-range sharding for large sites** (this Epic)\n- Partition indexes by sequential episode ID ranges\n- No auth considerations yet\n- Test sites: `limitedresources` (already broken), `myfavoritemurder` (approaching limit)\n\n**Phase 2: Public/private sharding for auth** (Authenticated Feeds Epic)\n- Separate indexes for public vs. private episodes\n- Builds on orchestration infrastructure from Phase 1\n\n## Proposed Solution\n\nAdd an optional **Search Orchestrator Lambda** that:\n1. Receives search requests from the client\n2. Distributes queries to multiple downstream search Lambdas (sharded by episode range)\n3. Aggregates results by relevancy score\n4. Handles pagination and sorting across distributed results\n5. Returns unified response to client\n\n### Configuration\n\nSites can configure in their terraform:\n- `enable_search_orchestrator = true/false` (default: false)\n- `search_lambda_count = N` (number of search shards, default: 1)\n- `search_shard_strategy = \"episode_range\"` (future: `public_private`)\n\n### Default Behavior\n\nMost sites will continue using a single search Lambda with no orchestrator. The orchestrator is opt-in for sites that need it.\n\n## Key Technical Considerations\n\n- Result merging with proper relevancy score handling (Orama BM25 scores)\n- Consistent pagination across shards\n- Cold start coordination (parallel warming of downstream Lambdas)\n- API Gateway timeout management (30s hard limit)\n- Index partitioning strategies during the indexing phase\n\n## Test Sites\n\n1. **limitedresources** - Already broken (OOM at 10GB), ~900 hours of audio, ~800+ episodes\n2. **myfavoritemurder** - Approaching limit (8GB), good canary for regression testing\n\n## Related Work\n\nThis Epic blocks the **Authenticated Feeds Support** Epic, which will add public/private sharding on top of this orchestration infrastructure.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-29T14:35:44.907703-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T14:47:47.481656-05:00"}
{"id":"bds-a8r.1","title":"Planning: Search Orchestration Architecture","description":"## Objective\n\nPlan the architecture for the optional search orchestration Lambda. **Focus on episode-range sharding first** to unblock large sites like `limitedresources` (already broken) and `myfavoritemurder` (approaching limit).\n\n## Key Questions to Resolve\n\n### 1. Orchestration vs. Direct Access\n- When orchestrator is disabled (default), client hits search Lambda directly (current behavior)\n- When enabled, client hits orchestrator, which fans out to search Lambdas\n- How to make this transparent to the client? Same API contract?\n\n### 2. Result Merging Strategy\n- Orama uses BM25 scoring - are scores comparable across different indexes?\n- How to merge relevancy-sorted results from multiple shards?\n- How to handle pagination across shards (offset/limit distribution)?\n\n### 3. Episode-Range Sharding (Primary Focus)\n- Partition by sequential episode ID ranges (e.g., episodes 1-400, 401-800)\n- How to determine optimal shard boundaries? (memory-based? episode count?)\n- How does the indexing Lambda know which shard to write to?\n- Future: public/private sharding will be added in Auth Epic\n\n### 4. Cold Start Management\n- Orchestrator needs to handle slow cold starts of downstream Lambdas\n- Parallel invocation with timeout handling\n- Warming strategy for multi-Lambda setups (EventBridge for each shard?)\n\n### 5. Configuration Model\n- Terraform variables needed for orchestrator setup\n- How to configure shard boundaries/strategy\n- Backward compatibility for existing single-Lambda sites\n\n### 6. API Gateway Considerations\n- 30-second hard timeout limit\n- Does orchestrator need different timeout than search Lambdas?\n- Error handling when one shard fails\n\n### 7. Index Partitioning During Ingestion\n- How does srt-indexing-lambda create multiple indexes?\n- Naming convention for sharded index files in S3 (e.g., `search-index-shard-1.msgpack.zst`)\n- Manifest updates to track which episodes are in which shard\n\n## Test Plan\n\nBoth test sites should work throughout implementation:\n1. **limitedresources** - Currently broken, this Epic should fix it\n2. **myfavoritemurder** - Currently working, should not regress\n\n## Deliverables\n\n1. Architecture decision document\n2. Sequence diagrams for orchestrated search flow\n3. Updated Epic description with chosen approach\n4. Breakdown of implementation tasks","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-29T14:39:05.628078-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T15:26:57.972975-05:00","closed_at":"2025-12-29T15:26:57.972975-05:00","close_reason":"Closed","dependencies":[{"issue_id":"bds-a8r.1","depends_on_id":"bds-a8r","type":"parent-child","created_at":"2025-12-29T14:39:05.633335-05:00","created_by":"daemon"}],"comments":[{"id":1,"issue_id":"bds-a8r.1","author":"jackkoppa","text":"Draft architecture document created at docs/architecture/search-orchestration.md - ready for review with open questions on sharding strategy, result merging, pagination, and error handling.","created_at":"2025-12-29T19:58:34Z"},{"id":2,"issue_id":"bds-a8r.1","author":"jackkoppa","text":"Architecture planning complete. Documents created:\n- docs/architecture/search-orchestration.md (main doc)\n- docs/architecture/search-orchestration-diagrams.md (ASCII diagrams)\n\nImplementation tasks created as children of bds-a8r:\n- bds-a8r.2: Phase 1 - Constants \u0026 Search Lambda\n- bds-a8r.3: Phase 2 - Orchestrator Lambda  \n- bds-a8r.4: Phase 3 - Indexing Lambda\n- bds-a8r.5: Phase 4 - Terraform\n- bds-a8r.6: Phase 5 - Testing\n\nReady for review before closing this planning task.","created_at":"2025-12-29T20:02:39Z"}]}
{"id":"bds-a8r.2","title":"Phase 1: Add sharding support to constants and search Lambda","description":"## Objective\nAdd foundational sharding support without changing current behavior.\n\n## Tasks\n\n### 1.1 Constants/Config updates\n- Add SHARD_ID and SHARD_COUNT env var handling to packages/constants\n- Add getShardedSearchIndexKey(shardId) function\n- Add shard manifest types to packages/types\n\n### 1.2 Search Lambda shard awareness  \n- Modify search-indexed-transcripts.ts to read SHARD_ID env var\n- When SHARD_ID set: load search-index/shard-{N}/orama_index.msp\n- When SHARD_ID not set: behave exactly as today (backward compatible)\n\n## Acceptance Criteria\n- [ ] New constants functions added\n- [ ] Search Lambda works with and without SHARD_ID\n- [ ] No regression on existing sites (myfavoritemurder still works)\n\n## Estimate: 2-3 days","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-29T15:01:52.050785-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T15:01:52.050785-05:00","dependencies":[{"issue_id":"bds-a8r.2","depends_on_id":"bds-a8r","type":"parent-child","created_at":"2025-12-29T15:01:52.054197-05:00","created_by":"daemon"}]}
{"id":"bds-a8r.3","title":"Phase 2: Create search orchestrator Lambda","description":"## Objective\nCreate new Lambda that coordinates searches across multiple shard Lambdas.\n\n## Tasks\n\n### 2.1 Create search-orchestrator-lambda package\n- New package at packages/search/search-orchestrator-lambda/\n- Handler: receives request, fans out to shards, merges results\n- Include health check support for warming\n\n### 2.2 Score normalization for result merging\n- Over-fetch: request limit * 2 from each shard\n- Normalize scores within each shard to 0-1 scale\n- Merge all normalized results\n- Sort by normalized score descending\n- Return top limit results\n\n### 2.3 Proper distributed pagination\n- Get total counts from each shard (cache if possible)\n- Calculate proportional offsets based on result distribution\n- Handle edge cases when shards return fewer results than expected\n- Ensure consistent results across pages\n\n### 2.4 Partial results on shard failure\n- If a shard times out or errors, return results from successful shards\n- Mark response as partial: { partial: true, failedShards: [N] }\n- Log failures with clear context (shard ID, error type, duration)\n\n## Acceptance Criteria\n- [ ] Orchestrator Lambda package created\n- [ ] Can invoke multiple shard Lambdas in parallel\n- [ ] Results merged with score normalization\n- [ ] Pagination works correctly across pages\n- [ ] Partial results returned on shard failure\n- [ ] Health check warming works\n\n## Estimate: 3-4 days (increased due to proper pagination/normalization)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-29T15:02:02.738346-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T15:22:11.56912-05:00","dependencies":[{"issue_id":"bds-a8r.3","depends_on_id":"bds-a8r","type":"parent-child","created_at":"2025-12-29T15:02:02.740254-05:00","created_by":"daemon"},{"issue_id":"bds-a8r.3","depends_on_id":"bds-a8r.2","type":"blocked-by","created_at":"2025-12-29T15:02:02.743006-05:00","created_by":"daemon"}]}
{"id":"bds-a8r.4","title":"Phase 3: Update indexing Lambda for sharded output","description":"## Objective\nModify indexing Lambda to create multiple sharded indexes when configured.\n\n## Tasks\n\n### 3.1 Update srt-indexing-lambda for sharding\n- Read SHARD_COUNT from environment (default: 1 = no sharding)\n- When SHARD_COUNT \u003e 1:\n  - Calculate episode ranges per shard (auto-distribute by episode count)\n  - Create N separate Orama indexes\n  - Save to search-index/shard-{N}/orama_index.msp\n  - Generate search-index/shard-manifest.json\n- When SHARD_COUNT = 1: behave exactly as today\n\n### 3.2 Shard manifest generation\n- Manifest includes: shard count, episode ranges, index paths, timestamps, total episodes\n\n## Acceptance Criteria\n- [ ] Indexing creates sharded indexes when SHARD_COUNT \u003e 1\n- [ ] Shard manifest generated with correct metadata\n- [ ] No regression when SHARD_COUNT = 1 (default)\n- [ ] Episode distribution is roughly even across shards\n\n## Estimate: 2-3 days","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-29T15:02:10.274913-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T15:02:10.274913-05:00","dependencies":[{"issue_id":"bds-a8r.4","depends_on_id":"bds-a8r","type":"parent-child","created_at":"2025-12-29T15:02:10.276636-05:00","created_by":"daemon"},{"issue_id":"bds-a8r.4","depends_on_id":"bds-a8r.2","type":"blocked-by","created_at":"2025-12-29T15:02:10.279023-05:00","created_by":"daemon"}]}
{"id":"bds-a8r.5","title":"Phase 4: Terraform infrastructure changes","description":"## Objective\nAdd terraform configuration for conditional orchestrator deployment.\n\n## Tasks\n\n### 4.1 Add new terraform variables\n- enable_search_orchestrator (bool, default: false)\n- search_shard_count (number, default: 2, validation: 2-10)\n\n### 4.2 Conditional Lambda creation\n- When enable_search_orchestrator = true:\n  - Create orchestrator Lambda\n  - Create N shard Lambdas  \n  - Don't create single search Lambda\n- When enable_search_orchestrator = false:\n  - Create single search Lambda (current behavior)\n\n### 4.3 Update API Gateway integration\n- Point to orchestrator when enabled, single Lambda when disabled\n\n### 4.4 Update EventBridge warming\n- Warm orchestrator (which triggers shard warming) when enabled\n\n### 4.5 IAM permissions\n- Orchestrator needs lambda:InvokeFunction on all shard Lambdas\n\n## Acceptance Criteria\n- [ ] New variables added to variables.tf\n- [ ] Conditional resource creation works correctly\n- [ ] API Gateway routes to correct Lambda\n- [ ] Warming schedule works for both modes\n- [ ] terraform plan shows no changes for existing sites\n\n## Estimate: 1-2 days","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-29T15:02:18.036731-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T15:02:18.036731-05:00","dependencies":[{"issue_id":"bds-a8r.5","depends_on_id":"bds-a8r","type":"parent-child","created_at":"2025-12-29T15:02:18.038651-05:00","created_by":"daemon"},{"issue_id":"bds-a8r.5","depends_on_id":"bds-a8r.3","type":"blocked-by","created_at":"2025-12-29T15:02:18.042009-05:00","created_by":"daemon"}]}
{"id":"bds-a8r.6","title":"Phase 5: Testing and validation with real sites","description":"## Objective\nValidate orchestration works correctly with real production sites.\n\n## Tasks\n\n### 5.1 Regression test with myfavoritemurder\n- Deploy with enable_search_orchestrator = false\n- Verify no changes to behavior\n- Verify search still works correctly\n\n### 5.2 Test orchestration with limitedresources\n- Deploy with enable_search_orchestrator = true, search_shard_count = 2\n- Target ~7GB max per shard (keeps cold starts under 30s)\n- Run full indexing pipeline\n- Verify sharded indexes created in S3\n- Verify shard-manifest.json is correct\n- Test search returns correct results\n- Test pagination across multiple pages (verify consistency)\n- Test cold start behavior (should be \u003c 30s)\n\n### 5.3 Test partial results handling\n- Simulate shard failure (e.g., set one shard to timeout)\n- Verify partial results returned with correct metadata\n- Verify error logging is clear\n\n### 5.4 Performance validation\n- Compare search latency: single Lambda vs orchestrated\n- Measure cold start times for orchestrator + shards\n- Verify memory usage per shard \u003c 7GB target\n\n## Test Sites\n- limitedresources: Currently broken (OOM), should work after this\n- myfavoritemurder: Currently working, should not regress\n\n## Acceptance Criteria\n- [ ] limitedresources fully functional with orchestration\n- [ ] myfavoritemurder unchanged (no regression)\n- [ ] Search latency acceptable (\u003c 2s warm, \u003c 30s cold)\n- [ ] Memory per shard \u003c 7GB\n- [ ] Pagination consistent across pages\n- [ ] Partial results work correctly\n\n## Estimate: 2-3 days","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-29T15:02:27.265467-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T15:22:26.64545-05:00","dependencies":[{"issue_id":"bds-a8r.6","depends_on_id":"bds-a8r","type":"parent-child","created_at":"2025-12-29T15:02:27.269079-05:00","created_by":"daemon"},{"issue_id":"bds-a8r.6","depends_on_id":"bds-a8r.5","type":"blocked-by","created_at":"2025-12-29T15:02:27.272092-05:00","created_by":"daemon"}]}
{"id":"bds-ajy","title":"Test with external-ref","description":"Test","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:31.65166-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:59:24.166654-05:00","closed_at":"2025-12-29T12:59:24.166654-05:00","close_reason":"Closed"}
{"id":"bds-bgn","title":"Test with no-daemon","description":"Test","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-29T12:57:21.414529-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:59:22.078758-05:00","closed_at":"2025-12-29T12:59:22.078758-05:00","close_reason":"Closed"}
{"id":"bds-cyk","title":"Fix hardcoded values in automation role deployment","description":"Test description\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:34.776809-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:34.776809-05:00","external_ref":"gh-123","labels":["bug-report"]}
{"id":"bds-drg","title":"Test issue after daemon stop","description":"Test","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:03.813957-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:59:24.269563-05:00","closed_at":"2025-12-29T12:59:24.269563-05:00","close_reason":"Closed"}
{"id":"bds-g9x","title":"Test issue","description":"Test","status":"closed","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:03.465747-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:59:24.323081-05:00","closed_at":"2025-12-29T12:59:24.323081-05:00","close_reason":"Closed"}
{"id":"bds-k92","title":"Site deploy does not work correctly","description":"## Bug Report\n\n**What's wrong?**\n\nDeployment to AWS fails\n\n**Steps to reproduce:**\n\n1. Run deploy to AWS step\n\n**Expected behavior:**\n\nIt should work :) Not sure what the issue is as even when I manually run source filename for the env files it does not pick up that these environment variables are set.\n\nThere is no issue with the AWS credentials as I was able to bootstrap the Terraform state bucket (with the change in https://github.com/jackkoppa/browse-dot-show/pull/100\n\n**Screenshots/Links:**\n\nMy configuration is at https://github.com/trevorrea/browse-dot-show\n\n‚úî Ready to setup aws deployment? ‚Ä∫ Yes, let's do it now! üöÄ\n\n‚ÑπÔ∏è  üöÄ Let's deploy your site to AWS!\n\nThis will set up your podcast site with:\n  ‚Ä¢ S3 static hosting with global CDN\n  ‚Ä¢ Lambda functions for search and processing\n  ‚Ä¢ Automatic SSL certificate\n  ‚Ä¢ Your custom browse.show subdomain\n\n‚ÑπÔ∏è  üîç Checking AWS CLI installation...\nüîß Executing: aws --version\n‚úÖ ‚úÖ AWS CLI is installed\n‚ÑπÔ∏è  üìã Found existing AWS configuration file...\n‚ÑπÔ∏è  Testing existing profile: iwltr-deploy\n‚úÖ ‚úÖ Existing AWS profile \"iwltr-deploy\" is working!\n‚úÖ ‚úÖ AWS credentials are configured and ready!\n‚ÑπÔ∏è  üîç Checking deployment prerequisites...\n\n‚ÑπÔ∏è  Checking required tools...\nüîß Executing: terraform --version\n‚úÖ ‚úÖ Terraform 1.12 is installed\n‚ÑπÔ∏è  Checking environment variables...\n‚ùå ‚ùå OPENAI_API_KEY environment variable is missing\n\nThis is required for:\n  ‚Ä¢ Podcast episode transcription\n  ‚Ä¢ Search functionality\n\n‚úî Do you have an OpenAI API key available? ‚Ä¶ yes\n‚úî Please enter your OpenAI API key: ‚Ä¶ **********\n\n‚ÑπÔ∏è  üîß Adding API key to your .env files...\n\nPlease add this line to the following files:\nOPENAI_API_KEY=\"sk-default\"\n\nFiles to update:\n  1. .env.local (for local development)\n  2. .env.lambda-prod-build (for production deployment)\n\n‚úî Have you added the OPENAI_API_KEY to both .env files? ‚Ä¶ yes\n‚úÖ ‚úÖ OpenAI API key configured for this session\n‚ÑπÔ∏è  ‚ÑπÔ∏è  AWS region set to default: us-east-1\n‚ÑπÔ∏è  Running comprehensive prerequisite checks...\nüîß Executing: tsx scripts/deploy/check-prerequisites.ts\n‚ùå Command failed with exit code 1\n   stderr: ‚ùå ‚ùå Site AWS SSO Configuration: AWS_PROFILE not found. Please ensure your site .env.aws-sso file contains AWS_PROFILE=your-profile-name\n‚ùå ‚ùå AWS SSO Authentication: AWS_PROFILE not set. Please ensure your site .env.aws-sso file contains AWS_PROFILE=your-profile-name\n‚ùå ‚ùå Some prerequisites are not met. Please fix the issues above before deploying.\n\n‚ùå ‚ùå Prerequisite check failed\n\n‚ÑπÔ∏è  Some prerequisites may not be met. Common issues:\n  ‚Ä¢ AWS CLI not configured properly\n  ‚Ä¢ Missing required permissions\n  ‚Ä¢ Network connectivity issues\n\n‚ÑπÔ∏è  You can try to continue anyway, but deployment may fail.\n‚úî Would you like to continue despite the prerequisite issues? ‚Ä¶ yes\n‚úÖ ‚úÖ Prerequisites and environment are ready!\n‚ÑπÔ∏è  üèóÔ∏è  Setting up Terraform state management...\n\nThis creates secure, shared storage for your site's infrastructure state.\nIt's a one-time setup that enables safe infrastructure management.\n\n‚ÑπÔ∏è  Checking if Terraform state is already configured...\n‚úÖ ‚úÖ Terraform state bucket already exists: browse-dot-show-iwltr-tf-state\n‚úÖ ‚úÖ Terraform backend configuration files are ready\n‚úÖ ‚úÖ Terraform state management is ready!\n\n‚ÑπÔ∏è  üöÄ Ready to deploy your site infrastructure!\n\nThis will deploy your complete podcast site with:\n  ‚Ä¢ S3 bucket for static hosting\n  ‚Ä¢ CloudFront CDN for global distribution\n  ‚Ä¢ Lambda functions for search and processing\n  ‚Ä¢ SSL certificate for secure HTTPS\n  ‚Ä¢ DNS configuration for your browse.show subdomain\n\n‚è±Ô∏è  Estimated deployment time: 10-15 minutes\nüí∞ Estimated monthly cost: $10-35 (depending on usage)\n\n‚úî Ready to deploy your podcast site to AWS? ‚Ä¶ yes\n‚ÑπÔ∏è  Setting up deployment environment...\n‚ÑπÔ∏è  Using AWS profile: iwltr-deploy\n\n‚ÑπÔ∏è  üöÄ Starting deployment...\n‚ÑπÔ∏è  This may take 10-15 minutes. You can watch the progress below.\n\n‚ùå ‚ùå Deployment encountered an error\n\nError details:\nrequire is not defined\n\n\n---\n**Note:** This issue is vague and may be superseded by more specific deployment bugs (#123-128). Please verify if still relevant.\n","status":"open","priority":2,"issue_type":"bug","created_at":"2025-12-29T12:57:49.160927-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:49.160927-05:00","external_ref":"gh-101","labels":["bug-report"]}
{"id":"bds-kbo","title":"FFmpeg layer creation script has directory issues","description":"The script to create FFmpeg layers puts files in wrong directory and errors out during execution. This was discovered during a user deployment attempt.\n\n**Code References:**\n- [`terraform/sites/lambda-layers/2-prepare-ffmpeg-layer.ts`](https://github.com/jackkoppa/browse-dot-show/blob/main/terraform/sites/lambda-layers/2-prepare-ffmpeg-layer.ts#L18-21) - directory paths\n\n**Requirements:**\n- Fix directory structure in ffmpeg layer preparation script\n- Ensure proper error handling and cleanup\n- Test layer creation process end-to-end\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:49.339316-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:49.339316-05:00","external_ref":"gh-126","labels":["bug-report"]}
{"id":"bds-kmy","title":"Add error monitoring infrastructure with Slack alerts","description":"## Objective\nSet up error monitoring that alerts in Slack when error counts get high.\n\n## Context\nCurrently we don't have great error monitoring. As we add orchestration complexity, we need visibility into:\n- Shard failures (timeouts, OOM, etc.)\n- API Gateway timeouts\n- Cold start failures\n\n## Requirements\n- Aggregate error logs from Lambda CloudWatch\n- Alert to Slack when error rate exceeds threshold\n- Include context: site ID, shard ID (if applicable), error type\n\n## Options to Explore\n- CloudWatch Alarms ‚Üí SNS ‚Üí Slack webhook\n- CloudWatch Logs Insights queries on schedule\n- Third-party (Datadog, etc.) - probably overkill\n\n## Notes\nThis is not blocking for search orchestration, but should be done soon after.\nDiscovered during bds-a8r.1 planning.","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-29T15:21:35.936447-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T15:21:35.936447-05:00"}
{"id":"bds-ofv","title":"Authenticated Feeds Support","description":"## Overview\n\nEnable browse.show sites to support searching and playing episodes from authenticated/paid podcast feeds. Primary use case: Patreon subscribers can log in via OAuth and search premium content alongside public episodes.\n\n## Problem Statement\n\nCurrently, all browse.show sites only support public RSS feeds. However, many podcasts offer premium content through platforms like Patreon, where subscribers get access to bonus episodes via private RSS feeds.\n\nSite deployers who have legitimate access to these paid feeds (working with podcast creators who opt-in) want to:\n1. Index both public AND private episodes\n2. Allow users to authenticate via the original payment platform (e.g., Patreon OAuth)\n3. Show public episodes to everyone, private episodes only to authenticated users\n4. Seamlessly search across both when logged in\n\n## Implementation Approach\n\n### Phase 1: Patreon-Specific Implementation\nStart with Patreon OAuth only. Design should include TODOs for future extensibility.\n\n**TODO: Future OAuth Providers to Support**\n- Supportingcast API: https://developers.supportingcast.fm/api\n- Apple Podcasts Subscriptions\n- Spotify for Podcasters paid subscriptions\n- Generic RSS feed auth (basic auth, token-based)\n\n### Phase 2: Multi-Provider Support (Future)\nRefactor to pluggable provider architecture based on learnings from Patreon implementation.\n\n## Assumptions\n\n- The site deployer has legitimate access to the paid RSS feed (coordinating with podcast creators)\n- The deployer can download and process MP3s from the paid feed\n- Authorization is handled externally (e.g., Patreon verifies the user has an active subscription)\n- We only need to verify the user is authorized, not handle payments\n\n## Proposed Solution\n\n### Authentication Flow\n1. User clicks Login on a site that supports authenticated feeds\n2. Redirected to Patreon OAuth\n3. Patreon verifies user has active subscription to the relevant tier\n4. User redirected back with auth token\n5. Token stored (see Auth Persistence Spike for approach)\n6. Search requests include auth context\n\n### Search Orchestration (requires Search Orchestration Lambda Epic)\n- Unauthenticated users: Search only the public index\n- Authenticated users: Orchestrator searches both public AND private indexes, merges results\n\n### Index Structure\n- Separate Orama indexes: one for public episodes, one for private episodes\n- Indexing Lambda creates both during processing\n- Episode manifest tracks which episodes are public vs. private\n\n## Key Technical Considerations\n\n- **Session/Auth Persistence**: See Spike bds-ofv.2 (must complete before planning)\n- **Audio Playback Restrictions**: See Spike bds-ofv.3 (serve audio only to authenticated users)\n- **Patreon OAuth Integration**: Token refresh, tier mapping to feed access\n- **Token Security**: Short-lived tokens, secure storage, proper CORS\n- **Graceful Degradation**: If auth fails, show only public content\n- **UI/UX**: Login/logout states, clear indication of private vs. public content\n\n## Dependencies\n\n**Blocked by:** Search Orchestration Lambda Epic (bds-a8r) - Requires orchestration layer to coordinate public/private index searches.","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-29T14:38:34.613594-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T14:48:25.368608-05:00","dependencies":[{"issue_id":"bds-ofv","depends_on_id":"bds-a8r","type":"blocked-by","created_at":"2025-12-29T14:38:34.623542-05:00","created_by":"daemon"}]}
{"id":"bds-ofv.1","title":"Planning: Authenticated Feeds Architecture","description":"## Objective\n\nCollaboratively plan the architecture for authenticated feeds support. This is a planning/discovery task to align on approach before implementation begins.\n\n**Note:** This planning task is blocked by the Auth Session Persistence Spike (bds-ofv.2), which must complete first to inform key architectural decisions.\n\n## Key Questions to Resolve\n\n### 1. Patreon OAuth Integration (Phase 1)\n- Patreon OAuth flow implementation\n- How to map Patreon tiers to feed access permissions?\n- Token refresh strategy (Patreon tokens expire)\n- **TODO for future**: Design extensibility for Supportingcast, Apple Podcasts, Spotify, etc.\n\n### 2. Session/Auth Persistence\n- **Depends on Spike bds-ofv.2 results**\n- Chosen approach will be documented here after spike completion\n\n### 3. Index Architecture\n- How to mark episodes as public vs. private in the manifest?\n- Separate S3 paths for public/private indexes?\n- How does the indexing Lambda know which episodes go where?\n\n### 4. Site Configuration\n- How does a site opt-in to authenticated feeds?\n- What config is needed in site.config.json and terraform?\n- Patreon client ID/secret management\n\n### 5. Client-Side UX\n- Login/logout UI components\n- How to indicate private vs. public episodes in search results?\n- What happens when auth token expires mid-session?\n\n### 6. Audio Playback Restrictions\n- **Depends on Spike bds-ofv.3 results**\n- Chosen approach will be documented here after spike completion\n\n### 7. Security Considerations\n- CORS configuration for auth endpoints\n- Token storage best practices\n- Rate limiting for auth endpoints\n\n## Deliverables\n\n1. Architecture decision document\n2. Updated Epic description with chosen approach\n3. Breakdown of implementation tasks\n4. Identification of any additional spikes needed\n\n## Collaboration Notes\n\nThis task is for collaborative planning between the deployer and development assistance. We'll iterate on the design before breaking into implementation tasks.\n\n## Dependencies\n\n- **Blocked by:** Auth Session Persistence Spike (bds-ofv.2)\n- **Informed by:** Authenticated Audio Playback Spike (bds-ofv.3)","status":"open","priority":1,"issue_type":"task","created_at":"2025-12-29T14:38:50.852731-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T14:49:06.686594-05:00","dependencies":[{"issue_id":"bds-ofv.1","depends_on_id":"bds-ofv","type":"parent-child","created_at":"2025-12-29T14:38:50.864814-05:00","created_by":"daemon"},{"issue_id":"bds-ofv.1","depends_on_id":"bds-ofv.2","type":"blocks","created_at":"2025-12-29T14:48:53.636911-05:00","created_by":"daemon"}]}
{"id":"bds-ofv.2","title":"Spike: Auth Session Persistence Options","description":"## Objective\n\nResearch and evaluate options for auth session/token persistence with minimal infrastructure overhead. Currently, browse.show has no database by design (simplicity and cost). Determine if we can maintain this, or what minimal persistence is required for OAuth.\n\n## Context\n\n- browse.show currently has no database - all data is in S3 (static files, indexes)\n- This is intentional for simplicity and to minimize AWS costs\n- OAuth flows typically require some session/token storage\n- Goal: Find the most minimal solution that still provides good UX\n\n## Options to Evaluate\n\n### 1. Client-Side Only (No Backend Persistence)\n- Store JWT/tokens in localStorage or httpOnly cookies\n- Pros: Zero infrastructure, works with static hosting\n- Cons: Token refresh complexity, security considerations\n- Questions: Can Patreon tokens be validated client-side? CORS issues?\n\n### 2. Single Shared DynamoDB Table (All Sites)\n- One DynamoDB table for all browse.show sites\n- Minimal read/writes (only on login, token refresh)\n- Pay-per-request pricing (no provisioned capacity)\n- Pros: Simple, cheap at low scale, serverless\n- Cons: Adds infrastructure, cross-site considerations\n\n### 3. Lambda@Edge Token Validation\n- Validate tokens at CloudFront edge\n- Cache validation results\n- Pros: Fast, close to user\n- Cons: Lambda@Edge complexity, cold starts at edge\n\n### 4. Third-Party Auth Service\n- Auth0, Clerk, Supabase Auth, etc.\n- Pros: Handles complexity, good SDKs\n- Cons: Additional cost, external dependency, may be overkill\n\n### 5. Stateless Token Approach\n- Short-lived tokens only, no server-side sessions\n- Re-auth on token expiry\n- Pros: No persistence needed\n- Cons: Poor UX if tokens expire frequently\n\n## Evaluation Criteria\n\n1. **Cost**: Monthly cost at various scales (10, 100, 1000 active users)\n2. **Complexity**: Infrastructure and code complexity\n3. **Security**: Token handling best practices\n4. **UX**: Login frequency, session duration\n5. **Maintenance**: Ongoing operational burden\n\n## Deliverables\n\n1. Comparison matrix of options\n2. Recommendation with rationale\n3. Rough cost estimates\n4. POC if needed for validation\n\n## Note\n\nThis spike informs the Authenticated Feeds planning task. May be done in parallel or sequentially depending on planning needs.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-29T14:39:24.342286-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T14:39:24.342286-05:00","dependencies":[{"issue_id":"bds-ofv.2","depends_on_id":"bds-ofv","type":"parent-child","created_at":"2025-12-29T14:39:24.345694-05:00","created_by":"daemon"}]}
{"id":"bds-ofv.3","title":"Spike: Authenticated Audio Playback","description":"## Objective\n\nResearch and evaluate options for restricting audio file playback to authenticated users only. Currently, audio files are served directly from S3 via CloudFront with no access restrictions.\n\n## Problem Statement\n\nFor authenticated feeds, we need to ensure that:\n1. **Search results** for private episodes are only visible to authenticated users (handled by orchestration)\n2. **Audio files** for private episodes can only be played by authenticated users (this spike)\n\nWithout playback restrictions, someone could:\n- Discover private episode audio URLs (e.g., from browser network tab)\n- Share those URLs publicly\n- Bypass the authentication entirely for playback\n\n## Current Architecture\n\n- Audio files stored in S3: `audio/{podcast-id}/{episode-file}.wav`\n- Served via CloudFront CDN\n- No authentication layer - all files publicly accessible via CloudFront URL\n\n## Options to Evaluate\n\n### 1. CloudFront Signed URLs\n- Generate time-limited signed URLs for authenticated users\n- Lambda generates signed URL when user requests playback\n- Pros: Native AWS solution, no additional infrastructure\n- Cons: URL management complexity, caching considerations\n\n### 2. CloudFront Signed Cookies\n- Set signed cookie after authentication\n- CloudFront validates cookie on each request\n- Pros: Works for all requests in session, simpler than per-URL signing\n- Cons: Cookie management, cross-site considerations\n\n### 3. Lambda@Edge Authorization\n- Lambda@Edge function validates auth token on each request\n- Pros: Full control over auth logic\n- Cons: Cold starts at edge, added latency, cost\n\n### 4. S3 Presigned URLs (Bypass CloudFront)\n- Generate presigned S3 URLs directly\n- Pros: Simple to implement\n- Cons: Bypasses CDN caching, higher S3 costs, worse latency\n\n### 5. Separate CloudFront Distribution for Private Content\n- Public content: existing distribution (no auth)\n- Private content: new distribution with signed URLs/cookies\n- Pros: Clear separation, existing sites unaffected\n- Cons: More infrastructure, two distributions per site\n\n### 6. Origin Access Control with Lambda\n- CloudFront Origin Access Control + Lambda function URL as origin\n- Lambda validates auth and proxies to S3\n- Pros: Flexible\n- Cons: Complex, Lambda as proxy adds latency\n\n## Evaluation Criteria\n\n1. **Security**: How well does it prevent unauthorized access?\n2. **Performance**: Latency impact, CDN caching effectiveness\n3. **Complexity**: Implementation and maintenance burden\n4. **Cost**: Additional AWS costs at various scales\n5. **UX**: Seamless playback experience for authenticated users\n\n## Deliverables\n\n1. Comparison matrix of options\n2. Recommendation with rationale\n3. Proof of concept for recommended approach\n4. Integration plan with auth flow\n\n## Dependency\n\nThis spike should be completed alongside or after the Auth Persistence Spike (bds-ofv.2), as the chosen auth mechanism will influence this decision.","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-29T14:48:44.063042-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T14:48:44.063042-05:00","dependencies":[{"issue_id":"bds-ofv.3","depends_on_id":"bds-ofv","type":"parent-child","created_at":"2025-12-29T14:48:44.06488-05:00","created_by":"daemon"}]}
{"id":"bds-oiq","title":"Terraform deployment expects origin-sites instead of my-sites structure","description":"The deployment scripts hardcode paths to `origin-sites` directory but should support `my-sites` structure for user sites.\n\n**Code References:**\n- [`scripts/deploy/site-deploy.ts`](https://github.com/jackkoppa/browse-dot-show/blob/main/scripts/deploy/site-deploy.ts#L416-417) - hardcoded origin-sites paths\n\n**Requirements:**\n- Update deployment scripts to check my-sites first, then fallback to origin-sites\n- Ensure backend.tfbackend and prod.tfvars are found in correct directory\n- Test with my-sites structure\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:48.278902-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.278902-05:00","external_ref":"gh-125","labels":["bug-report"]}
{"id":"bds-v9u","title":"Show podcast name and cover art in search results for multi-feed sites","description":"For sites with multiple podcast feeds, search results should show which podcast each result comes from to help users distinguish sources.\n\n**Requirements:**\n- Add podcast name display to search result components\n- Optionally show podcast cover art in results\n- Make this configurable for single vs multi-feed sites\n- Update search index to include podcast metadata if needed\n","status":"open","priority":3,"issue_type":"feature","created_at":"2025-12-29T12:57:48.984095-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.984095-05:00","external_ref":"gh-131","labels":["feature-request","planned-feature"]}
{"id":"bds-vu2","title":"Lambda layers over 50MB need S3 upload instead of file upload","description":"FFmpeg layer is over 50MB and can't be loaded from zip file. A user (@trevorrea) had to manually upload to S3 and import into terraform state. Code should automatically upload to S3 and reference S3 object instead of filename.\n\n**Code References:**\n- [`terraform/sites/main.tf`](https://github.com/jackkoppa/browse-dot-show/blob/main/terraform/sites/main.tf#L77-86) - ffmpeg layer resource\n\n**Requirements:**\n- Automatically upload large layers to S3 during terraform deployment\n- Update terraform to reference S3 object instead of local file\n- Add lifecycle management to ignore filename changes when using S3\n","status":"open","priority":1,"issue_type":"bug","created_at":"2025-12-29T12:57:48.458109-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.458109-05:00","external_ref":"gh-127","labels":["bug-report"]}
{"id":"bds-zq6","title":"Re-attempt to add speaker diarization to transcripts","description":"## Feature Request\n\n**What feature would you like?**\nIdentify speakers in transcription\n\n**Why is this useful?**\nEasier to read transcripts when broken down this way. Can likely add filtering by speaker in the future, if it works well\n\n**Additional context:**\n* As of 2025-08-05, this isn't currently prioritized. I had attempted it when first setting up http://listenfairplay.com/ - at the time, I was primarily using the OpenAI API, which doesn't easily support this. I also explored https://whisperapi.com/, which could potentially support it.\n* I then attempted the local setup following this guide: https://github.com/ggml-org/whisper.cpp?tab=readme-ov-file#speaker-segmentation-via-tinydiarize-experimental\n* For listenfairplay, this worked poorly - likely in part because the show plays lots of clips (that are not the 3 main panelists) - and so the diarization often missed when speakers changed\n* In the end, I went with simply breaking up transcripts into searchable chunks by time (e.g. \"once a chunk is at least 7 seconds, end it after the next sentence-ending punctuation\")\n* This has _mostly_ worked well enough - and there's a decent amount of search indexing + UI behaviors that we'll need to update if we're able to get diarization working\n* So @jackkoppa is currently working on other things - but if someone is interested enough in this, please feel free to start experimenting, and happy to give feedback on any initial attempts!\n\n","status":"open","priority":4,"issue_type":"feature","created_at":"2025-12-29T12:57:48.102594-05:00","created_by":"jackkoppa","updated_at":"2025-12-29T12:57:48.102594-05:00","external_ref":"gh-111","labels":["feature-request","help-wanted"]}
